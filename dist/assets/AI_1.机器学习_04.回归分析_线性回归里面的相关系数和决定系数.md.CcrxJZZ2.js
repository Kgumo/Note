import{_ as o,c as e,o as l,a3 as d}from"./chunks/framework.CkaDlzKP.js";const f=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"AI/1.机器学习/04.回归分析/线性回归里面的相关系数和决定系数.md","filePath":"AI/1.机器学习/04.回归分析/线性回归里面的相关系数和决定系数.md","lastUpdated":1754900608000}'),r={name:"AI/1.机器学习/04.回归分析/线性回归里面的相关系数和决定系数.md"};function s(n,t,c,i,g,a){return l(),e("div",null,t[0]||(t[0]=[d('<p>在统计学和机器学习中，线性回归中的<strong>相关系数（Correlation Coefficient）</strong> 和<strong>决定系数（Coefficient of Determination）</strong> 都是衡量变量间关系强度的指标，但它们侧重点不同。下面详细解释两者的概念、计算、区别和联系：</p><hr><h3 id="_1-相关系数-通常指皮尔逊相关系数-r" tabindex="-1"><strong>1. 相关系数（通常指皮尔逊相关系数 <code>r</code>）</strong> <a class="header-anchor" href="#_1-相关系数-通常指皮尔逊相关系数-r" aria-label="Permalink to &quot;**1. 相关系数（通常指皮尔逊相关系数 `r`）**&quot;">​</a></h3><ul><li><strong>定义：</strong> 衡量两个连续变量 <code>X</code>（自变量）和 <code>Y</code>（因变量）之间<strong>线性关系强度</strong>和<strong>方向</strong>的统计量。</li><li><strong>范围：</strong> <code>-1 ≤ r ≤ 1</code></li><li><strong>意义：</strong><ul><li><code>r = 1</code>：完全正线性相关（所有点落在一条斜率为正的直线上）。</li><li><code>r = -1</code>：完全负线性相关（所有点落在一条斜率为负的直线上）。</li><li><code>r = 0</code>：<strong>无线性相关</strong>（但可能存在非线性关系！）。</li><li><code>|r|</code> 越大，线性关系越强。</li></ul></li><li><strong>公式：</strong><code>r = Σ[(Xi - X̄)(Yi - Ȳ)] / √[Σ(Xi - X̄)² * Σ(Yi - Ȳ)²]</code><ul><li><strong>解读：</strong> 计算的是 <code>X</code> 和 <code>Y</code> 各自与其均值偏差的乘积之和，再除以它们各自标准差的乘积的平方根。本质上是协方差的标准化。</li></ul></li><li><strong>特点：</strong><ul><li><strong>对称性：</strong> <code>r(X, Y) = r(Y, X)</code>。</li><li><strong>无量纲：</strong> 不受 <code>X</code> 和 <code>Y</code> 测量单位影响。</li><li><strong>仅度量线性关系：</strong> 无法捕捉非线性关联。</li><li><strong>相关≠因果：</strong> 仅表示统计关联，不能证明 <code>X</code> 导致 <code>Y</code>。</li></ul></li></ul><hr><h3 id="_2-决定系数-r2-或-r-squared" tabindex="-1"><strong>2. 决定系数（R² 或 R-squared）</strong> <a class="header-anchor" href="#_2-决定系数-r2-或-r-squared" aria-label="Permalink to &quot;**2. 决定系数（R² 或 R-squared）**&quot;">​</a></h3><ul><li><strong>定义：</strong> 衡量回归模型<strong>拟合优度</strong>的统计量。表示模型中<strong>自变量 <code>X</code> 能够解释因变量 <code>Y</code> 的总变异的比例</strong>。</li><li><strong>范围：</strong> <code>0 ≤ R² ≤ 1</code>（对于简单线性回归）。</li><li><strong>意义：</strong><ul><li><code>R² = 1</code>：模型完美拟合数据，所有点都在回归线上（此时 <code>|r| = 1</code>）。</li><li><code>R² = 0</code>：模型完全不能解释 <code>Y</code> 的变异（此时 <code>r = 0</code>）。</li><li><code>R²</code> 越接近 1，模型解释能力越强。</li></ul></li><li><strong>核心思想（变异分解）：</strong><ul><li><strong>总平方和（SST - Total Sum of Squares）：</strong> <code>Σ(Yi - Ȳ)²</code> - <code>Y</code> 自身总的变异。</li><li><strong>回归平方和（SSR - Regression Sum of Squares）：</strong> <code>Σ(Ŷi - Ȳ)²</code> - 模型解释的变异（预测值 Ŷ 围绕均值 Ȳ 的波动）。</li><li><strong>残差平方和（SSE - Error Sum of Squares）：</strong> <code>Σ(Yi - Ŷi)²</code> - 模型未能解释的变异（实际值 <code>Y</code> 偏离预测值 Ŷ 的程度）。</li><li><strong>关键等式：</strong> <code>SST = SSR + SSE</code></li></ul></li><li><strong>公式（基于变异分解）：</strong><code>R² = SSR / SST = 1 - (SSE / SST)</code><ul><li><strong>解读：</strong><ul><li><code>SSR / SST</code>：模型解释的变异占总变异的比例。</li><li><code>1 - (SSE / SST)</code>：总变异中未被模型解释的比例越小，<code>R²</code> 越大。</li></ul></li></ul></li><li><strong>特点：</strong><ul><li><strong>非对称性：</strong> <code>R²</code> 依赖于谁是因变量（<code>Y</code>）。</li><li><strong>模型评价：</strong> 核心目标是评估模型解释数据变动的能力。</li><li><strong>在简单线性回归中的关键联系：</strong> <code>R² = (r)^2</code><ul><li>简单线性回归（只有一个自变量 <code>X</code>）中，决定系数 <code>R²</code> 等于皮尔逊相关系数 <code>r</code> 的平方。</li><li>例如，若 <code>r = 0.8</code>，则 <code>R² = 0.64</code>，表示 <code>X</code> 解释了 <code>Y</code> 64% 的变异。</li></ul></li><li><strong>在多元线性回归中：</strong> <code>R²</code> 表示<strong>所有</strong>自变量共同解释的 <code>Y</code> 变异的比例，此时 <code>R²</code> 不再等于某个单一 <code>r</code> 的平方（通常报告调整 <code>R²</code> 以考虑自变量数量）。</li></ul></li></ul><hr><h3 id="相关系数-r-vs-决定系数-r2-核心区别与联系" tabindex="-1"><strong>相关系数（r） vs. 决定系数（R²）核心区别与联系</strong> <a class="header-anchor" href="#相关系数-r-vs-决定系数-r2-核心区别与联系" aria-label="Permalink to &quot;**相关系数（r） vs. 决定系数（R²）核心区别与联系**&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:left;">特性</th><th style="text-align:left;">相关系数（r）</th><th style="text-align:left;">决定系数（R²）</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>定义</strong></td><td style="text-align:left;">两变量<strong>线性关系强度与方向</strong></td><td style="text-align:left;">模型<strong>解释因变量变异比例</strong></td></tr><tr><td style="text-align:left;"><strong>范围</strong></td><td style="text-align:left;"><code>-1 ≤ r ≤ 1</code></td><td style="text-align:left;"><code>0 ≤ R² ≤ 1</code>（简单线性回归）</td></tr><tr><td style="text-align:left;"><strong>方向</strong></td><td style="text-align:left;">包含正负号（表示方向）</td><td style="text-align:left;">无方向（平方值）</td></tr><tr><td style="text-align:left;"><strong>对称性</strong></td><td style="text-align:left;">对称（<code>r(X, Y) = r(Y, X)</code>）</td><td style="text-align:left;">非对称（依赖于因变量）</td></tr><tr><td style="text-align:left;"><strong>主要用途</strong></td><td style="text-align:left;">描述两变量关联</td><td style="text-align:left;">评估回归模型拟合优度</td></tr><tr><td style="text-align:left;"><strong>关系（简单线性回归）</strong></td><td style="text-align:left;">-</td><td style="text-align:left;"><strong>R² = (r)²</strong></td></tr><tr><td style="text-align:left;"><strong>反映</strong></td><td style="text-align:left;">线性关联强度</td><td style="text-align:left;">模型预测能力（解释变异的比例）</td></tr><tr><td style="text-align:left;"><strong>单位</strong></td><td style="text-align:left;">无量纲</td><td style="text-align:left;">无量纲</td></tr><tr><td style="text-align:left;"><strong>多元回归</strong></td><td style="text-align:left;">通常指单个自变量与 <code>Y</code> 的 <code>r</code></td><td style="text-align:left;">所有自变量共同解释的变异比例</td></tr></tbody></table><hr><h3 id="重要注意事项" tabindex="-1"><strong>重要注意事项</strong> <a class="header-anchor" href="#重要注意事项" aria-label="Permalink to &quot;**重要注意事项**&quot;">​</a></h3><ol><li><strong><code>R²</code> 高不一定好：</strong><ul><li>过拟合：添加无关变量总会略微增加 <code>R²</code>（即使无真实关系），此时需看<strong>调整 <code>R²</code></strong>。</li><li>不代表因果关系。</li><li>可能受异常值影响。</li></ul></li><li><strong><code>r = 0</code> 不代表无关系：</strong> 只表示无<em>线性</em>关系，可能存在曲线关系（如 <code>U</code> 型）。</li><li><strong><code>R²</code> 与 <code>r</code> 的关系仅在简单线性回归中成立：</strong> 多元回归中 <code>R²</code> 反映整体解释力，不等于某个 <code>r</code> 的平方。</li><li><strong>选择：</strong><ul><li>想了解两个变量间线性关联的<strong>强度和方向</strong>？ → 用 <strong>相关系数 <code>r</code></strong>。</li><li>想评估建立的（线性）回归模型<strong>解释数据变异的能力</strong>？ → 用 <strong>决定系数 <code>R²</code></strong>。</li></ul></li></ol><hr><p><strong>总结：</strong></p><ul><li><strong>相关系数 <code>r</code></strong> 是你理解 <code>X</code> 和 <code>Y</code> 之间线性纽带有多紧密（及正负）的起点。</li><li><strong>决定系数 <code>R²</code></strong> 则是当你用 <code>X</code>（通过线性模型）去预测 <code>Y</code> 时，它能告诉你这个模型到底“抓住”了 <code>Y</code> 的多少变化规律。</li><li>在只有一个自变量的简单线性回归模型中，<code>R²</code> 就是 <code>r</code> 的平方，这是两者最直接的联系。但在更复杂的模型中，<code>R²</code> 承载了更丰富的模型评价信息。</li></ul>',16)]))}const _=o(r,[["render",s]]);export{f as __pageData,_ as default};
