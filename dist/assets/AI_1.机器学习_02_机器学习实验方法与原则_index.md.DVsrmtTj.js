import{_ as i,c as a,o as t,a3 as r}from"./chunks/framework.C3IOjdSt.js";const c=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"AI/1.机器学习/02,机器学习实验方法与原则/index.md","filePath":"AI/1.机器学习/02,机器学习实验方法与原则/index.md","lastUpdated":1754900608000}'),n={name:"AI/1.机器学习/02,机器学习实验方法与原则/index.md"};function o(e,l,s,u,g,d){return t(),a("div",null,l[0]||(l[0]=[r('<h3 id="实验方法与原则" tabindex="-1">实验方法与原则 <a class="header-anchor" href="#实验方法与原则" aria-label="Permalink to &quot;实验方法与原则&quot;">​</a></h3><h4 id="训练集与测试集" tabindex="-1"><strong>训练集与测试集</strong> <a class="header-anchor" href="#训练集与测试集" aria-label="Permalink to &quot;**训练集与测试集**&quot;">​</a></h4><ul><li><strong>训练集（Training Set）</strong>： <ul><li>模型可见样本标签，用于训练模型。</li><li>样本数量有限，以确保模型能够学习到数据的模式和特征。</li><li>潜在问题：可能存在过拟合，即模型在训练集上的表现好，但在其他未见样本上的表现差。</li></ul></li><li><strong>测试集（Test Set）</strong>： <ul><li>用于评估模型在可能遇到的未见样本上的表现。</li><li>尽可能与训练集互斥，即测试样本尽量不在训练集中出现，以确保测试集的独立性和鲁棒性。</li><li>目标：估计模型在整个未见样本上的表现。</li></ul></li></ul><h4 id="训练集、验证集与测试集" tabindex="-1"><strong>训练集、验证集与测试集</strong> <a class="header-anchor" href="#训练集、验证集与测试集" aria-label="Permalink to &quot;**训练集、验证集与测试集**&quot;">​</a></h4><ul><li>完整的数据集被分为三个部分： <ol><li><strong>训练集（Training Set）</strong>：用于训练模型。</li><li><strong>验证集（Validation Set）</strong>：用于调整模型、优化超参数。</li><li><strong>测试集（Test Set）</strong>：用于评估最终模型的效果。</li></ol></li><li>流程： <ol><li>训练模型；</li><li>使用验证集调整模型和超参数；</li><li>再次训练模型；</li><li>使用测试集评估最终模型。</li></ol></li></ul><h3 id="评价指标" tabindex="-1">评价指标 <a class="header-anchor" href="#评价指标" aria-label="Permalink to &quot;评价指标&quot;">​</a></h3><p>在不同任务下衡量模型的性能有不同的评价指标。</p><h4 id="回归任务" tabindex="-1"><strong>回归任务</strong> <a class="header-anchor" href="#回归任务" aria-label="Permalink to &quot;**回归任务**&quot;">​</a></h4><ul><li><strong>平均绝对误差（MAE）</strong>：实际值与预测值之差的绝对值的平均值。</li><li><strong>均方误差（MSE）</strong>：实际值与预测值之差的平方的平均值。</li><li><strong>均方根误差（RMSE）</strong>：MSE的平方根。</li></ul><h4 id="分类任务" tabindex="-1"><strong>分类任务</strong> <a class="header-anchor" href="#分类任务" aria-label="Permalink to &quot;**分类任务**&quot;">​</a></h4><ul><li><strong>准确率（Accuracy）</strong>：预测正确的样本数占总样本数的比例。</li><li><strong>精度（Precision）</strong>：在预测为正的样本中，实际为正的比例。</li><li><strong>召回率（Recall）</strong>：在实际为正的样本中，被预测为正的比例。</li></ul><h4 id="特定任务" tabindex="-1"><strong>特定任务</strong> <a class="header-anchor" href="#特定任务" aria-label="Permalink to &quot;**特定任务**&quot;">​</a></h4><ul><li><strong>个性化推荐系统</strong>： <ul><li><strong>前K项精度（Precision@K）</strong>：前K项推荐中，正例（用户喜欢的项目）的比例。</li><li><strong>前K项召回率（Recall@K）</strong>：前K项推荐中，正例数占候选集中所有正例的比例。</li><li><strong>前K项命中率（Hit@K）</strong>：前K项推荐中是否有正例。</li><li>其他指标：nDCG@K、点击率、用户留存、利润转化等。</li></ul></li><li><strong>对话系统</strong>： <ul><li><strong>BLEU、ROUGE、METEOR</strong>：基于词、n-gram匹配衡量预测句子与目标句子之间的相似度。</li><li>基于词向量计算预测句子与目标句子之间的相似度。</li><li>其他指标：用户与系统对话的时长、次数、人工评价等。</li></ul></li></ul><h4 id="相关性指标" tabindex="-1"><strong>相关性指标</strong> <a class="header-anchor" href="#相关性指标" aria-label="Permalink to &quot;**相关性指标**&quot;">​</a></h4><ul><li><strong>Discounted Cumulative Gain (DCG)</strong>： <ul><li>使用分级的相关性来衡量文档有用性或增益。</li><li>增益从排序列表的开头开始累积，随着位次增加，增益可能会减弱（折损）。</li><li>典型的折损函数为 ( \\frac{1}{\\log(rank)} )。</li><li>例如，底数为2时，位次4的折损为 (\\frac{1}{2})，位次8为 (\\frac{1}{3})。</li></ul></li></ul><h4 id="bleu-bilingual-evaluation-understudy" tabindex="-1"><strong>BLEU（Bilingual Evaluation Understudy）</strong> <a class="header-anchor" href="#bleu-bilingual-evaluation-understudy" aria-label="Permalink to &quot;**BLEU（Bilingual Evaluation Understudy）**&quot;">​</a></h4><ul><li>最初多用于机器翻译，后来也被其他任务借鉴（如对话生成等）。</li><li>检测译文中的每个n-gram是否在参考译文中出现。</li><li>精确率考虑词出现的次数限制，确保某个词在译文中的有效频次不应超过参考译文中的频次。</li></ul><h3 id="统计有效性检验" tabindex="-1">统计有效性检验 <a class="header-anchor" href="#统计有效性检验" aria-label="Permalink to &quot;统计有效性检验&quot;">​</a></h3><h4 id="比较算法的优劣" tabindex="-1"><strong>比较算法的优劣</strong> <a class="header-anchor" href="#比较算法的优劣" aria-label="Permalink to &quot;**比较算法的优劣**&quot;">​</a></h4><ul><li><strong>显著性检验</strong>：比较两个算法的平均准确率是否有显著差异。</li><li>**样本量较大（( n &gt; 30 )）**时，使用 <strong>z检验</strong>（基于中心极限定理）。</li><li>**样本量较小（( n &lt;= 30 )）**时，使用 <strong>t检验</strong>。</li></ul><p>这些方法能帮助你评价模型在不同类型任务中的表现，并通过统计检验确认模型性能的显著性。</p>',21)]))}const b=i(n,[["render",o]]);export{c as __pageData,b as default};
